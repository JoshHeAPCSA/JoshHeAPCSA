{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFYqBmopXZba"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "fingerprint_vgg16\n",
        "=====================\n",
        "An example end-to-end script for training a VGG16-based CNN\n",
        "to classify damaged fingerprint images.\n",
        "\n",
        "Folder structure assumption:\n",
        "  data/\n",
        "    train/\n",
        "      class1/\n",
        "        img_1.jpg\n",
        "        img_2.jpg\n",
        "        ...\n",
        "      class2/\n",
        "        img_1.jpg\n",
        "        img_2.jpg\n",
        "        ...\n",
        "      ...\n",
        "    val/\n",
        "      class1/\n",
        "        ...\n",
        "      class2/\n",
        "        ...\n",
        "    test/\n",
        "      class1/\n",
        "        ...\n",
        "      class2/\n",
        "        ...\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "###########################\n",
        "# 1. USER-DEFINED PARAMS  #\n",
        "###########################\n",
        "\n",
        "# Paths to your dataset folders\n",
        "TRAIN_DIR = \"data/train\"\n",
        "VAL_DIR   = \"data/val\"\n",
        "TEST_DIR  = \"data/test\"\n",
        "\n",
        "# Model checkpoints/logs\n",
        "CHECKPOINT_PATH = \"checkpoints/vgg16_fingerprint_best.h5\"\n",
        "LOG_DIR = \"logs\"\n",
        "\n",
        "# Image parameters\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH  = 224\n",
        "CHANNELS   = 3  # If your fingerprints are grayscale, set this to 1 and adapt accordingly.\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Training hyperparameters\n",
        "EPOCHS      = 20\n",
        "LR          = 1e-4\n",
        "DROPOUT_RATE = 0.3\n",
        "\n",
        "###########################\n",
        "# 2. DATA AUGMENTATION    #\n",
        "###########################\n",
        "\n",
        "# For damaged fingerprints, you may want robust augmentations:\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=False,   # Usually fingerprints aren't flipped horizontally, but you can experiment\n",
        "    vertical_flip=False,     # Same note as above\n",
        "    # You could add custom “damage simulation” here if desired\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# If you have separate test data:\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "###########################\n",
        "# 3. DATA LOADERS         #\n",
        "###########################\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=TRAIN_DIR,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',  # or 'sparse' if you prefer\n",
        "    color_mode='rgb' if CHANNELS == 3 else 'grayscale',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    directory=VAL_DIR,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb' if CHANNELS == 3 else 'grayscale',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=TEST_DIR,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb' if CHANNELS == 3 else 'grayscale',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "num_classes = train_generator.num_classes\n",
        "print(f\"Detected {num_classes} classes in the training set.\")\n",
        "\n",
        "###################################\n",
        "# 4. BUILD THE VGG16-BASED MODEL  #\n",
        "###################################\n",
        "\n",
        "# Load pretrained VGG16 (on ImageNet) without the top/classifier layers\n",
        "# If your images are grayscale, you'd need to tweak input_shape=(224,224,1)\n",
        "base_model = VGG16(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS)\n",
        ")\n",
        "\n",
        "# Freeze the early layers so they act as a fixed feature extractor\n",
        "# You can experiment with how many layers to freeze/unfreeze\n",
        "for layer in base_model.layers[:10]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add a custom classification head\n",
        "x = base_model.output\n",
        "# Option 1: Flatten\n",
        "# x = Flatten()(x)\n",
        "\n",
        "# Option 2: GlobalAveragePooling2D (usually better)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(DROPOUT_RATE)(x)\n",
        "# You can add more dense layers if needed\n",
        "\n",
        "# Final output layer for classification\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Build the full model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Print a summary to see the trainable parameters\n",
        "model.summary()\n",
        "\n",
        "###################################\n",
        "# 5. COMPILE THE MODEL            #\n",
        "###################################\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=LR),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "###################################\n",
        "# 6. TRAINING CALLBACKS           #\n",
        "###################################\n",
        "\n",
        "# Early stopping to prevent overfitting\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Model checkpoint to save the best model\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=CHECKPOINT_PATH,\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "callbacks_list = [early_stop, checkpoint]\n",
        "\n",
        "###################################\n",
        "# 7. FIT / TRAIN THE MODEL        #\n",
        "###################################\n",
        "steps_per_epoch   = train_generator.samples // BATCH_SIZE\n",
        "validation_steps  = val_generator.samples // BATCH_SIZE\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=callbacks_list\n",
        ")\n",
        "\n",
        "###################################\n",
        "# 8. EVALUATE ON THE TEST SET     #\n",
        "###################################\n",
        "print(\"\\nEvaluating on the test set...\")\n",
        "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "###################################\n",
        "# 9. SAVE THE TRAINED MODEL       #\n",
        "###################################\n",
        "# If you want to save the final model (even if not the best)\n",
        "final_model_path = \"vgg16_fingerprint_final.h5\"\n",
        "model.save(final_model_path)\n",
        "print(f\"Model saved to {final_model_path}\")\n",
        "\n",
        "###################################\n",
        "# 10. OPTIONAL: PLOT RESULTS      #\n",
        "###################################\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(history):\n",
        "    # Accuracy\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Loss\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history)\n"
      ]
    }
  ]
}